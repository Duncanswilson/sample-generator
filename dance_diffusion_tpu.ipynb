{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Duncanswilson/sample-generator/blob/main/dance_diffusion_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRwrORLsarkk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harmonai-org/sample-generator/blob/main/Dance_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcTRGvUmoME"
      },
      "source": [
        "# Dance Diffusion v0.12\n",
        "\n",
        "Welcome to the Dance Diffusion beta!\n",
        "\n",
        "Dance Diffusion is the first in a suite of generative audio tools for producers and musicians to be released by Harmonai. For more info or to get involved in the development of these tools, please visit https://harmonai.org and fill out the form on the front page.\n",
        "\n",
        "[Click here to ensure you are using the latest version](https://colab.research.google.com/github/Harmonai-org/sample-generator/blob/main/Dance_Diffusion.ipynb)\n",
        "\n",
        "**Audio diffusion tools in this notebook**:\n",
        "\n",
        "- Unconditional random audio sample generation\n",
        "- Audio sample regeneration/style transfer using a single audio file or recording\n",
        "- Audio interpolation between two audio files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iZwJ9ong-pH"
      },
      "source": [
        "# Instructions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ITvsXU6hCAx"
      },
      "source": [
        "## Before anything else\n",
        "- Run the \"Setup\" section\n",
        "- Sign in to the Google Drive account you want to save your models in\n",
        "- Select the model you want to sample from in the \"Model settings\" section, this determines the length and sound of your samples\n",
        "- Select the sampler you want to use.\n",
        "- The `save_to_wandb` option futher down adds the ability to log your audio generations to [Weights & Biases](https://www.wandb.ai/site), an experiment tracking and model and data versioning tool.\n",
        "\n",
        "## For random sample generation\n",
        "- Choose the number of random samples you would like Dance Diffusion to generate for you \n",
        "- Choose the number of diffusion steps you would like Dance Diffusion to execute\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked\n",
        "- Run the cell under the \"Generate new sounds\" header\n",
        "\n",
        "## To regenerate your own sounds\n",
        "- Record a file, enter the path to an audio file you want to regenerate, or upload a file when prompted\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked\n",
        "- Run the cell under the \"Regenerate your own sounds\" header\n",
        "\n",
        "## To interpolate between two different sounds\n",
        "- Enter the paths to two audio files you want to interpolate between, or upload them when prompted\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked\n",
        "- Run the cell under the \"Interpolate between sounds\" header\n",
        "\n",
        "## To regenerate sounds using built-in audio recording widget\n",
        "- Enter a path to save your audio recordings\n",
        "- Enter the number of audio recordings you want to combine into one\n",
        "- Run the cell under the \"Regenerate your own sound from the recording\" header\n",
        "- Make sure the \"skip_for_run_all\" checkbox is unchecked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJkAc1j4pfAt"
      },
      "source": [
        "### Credits & License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjHsmepZqNMs"
      },
      "source": [
        "\n",
        "\n",
        "Original notebook by Zach Evans (https://github.com/zqevans, https://twitter.com/zqevans). \n",
        "\n",
        "Overall structure and setup code taken from Disco Diffusion (https://www.discodiffusion.com)\n",
        "\n",
        "Interpolation and audio display code from CRASH inference notebook (https://github.com/simonrouard/CRASH)\n",
        "\n",
        "Spruced up by Chris the Wizard (https://twitter.com/chris_wizard)\n",
        "\n",
        "Audio recording widget added by Niels Bantilan (https://twitter.com/cosmicBboy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97w34BXmust"
      },
      "source": [
        "Licensed under the MIT License\n",
        "\n",
        "Copyright (c) 2022 Zach Evans\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "aBF6kI89LJ5O"
      },
      "outputs": [],
      "source": [
        "#@title <- View Changelog\n",
        "skip_for_run_all = True #@param {type: 'boolean'}\n",
        "\n",
        "if skip_for_run_all == False:\n",
        "  print(\n",
        "      '''\n",
        "\n",
        "  v0.1 Update: Jul 30, 2022 - zqevans\n",
        "      \n",
        "      - Added Dance Diffusion notebook\n",
        "\n",
        "  v0.2 Update: Aug 8, 2022 - zqevans\n",
        "\n",
        "      - Moved to models trained on \n",
        "\n",
        "  v0.3 Update: Aug 11, 2022 - zqevans\n",
        "\n",
        "      - Reverted to old model architecture\n",
        "      - Fixed CRASH sampling code\n",
        "\n",
        "  v0.4 Update: Aug 16, 2022 - zqevans\n",
        "\n",
        "      - Added jmann-small-190k model\n",
        "\n",
        "  v0.5 Update: Aug 17, 2022 - zqevans\n",
        "\n",
        "      - Added interpolations\n",
        "    \n",
        "  v0.6 Update: Aug 18, 2022 - zqevans\n",
        "\n",
        "      - Fixed bug in interpolations\n",
        "\n",
        "  v0.7 Update: Aug 20, 2022 - zqevans\n",
        "      - Added maestro-150k model\n",
        "      - Added unlocked-250k model\n",
        "      - Improved documentation\n",
        "\n",
        "  v0.7.1 Update: Aug 21, 2022 - chris the wizard\n",
        "      - Added introduction\n",
        "      - Added instructions\n",
        "      - Added skips for sections\n",
        "      - Added upload prompts for audio files\n",
        "      - Removed stale demos\n",
        "\n",
        "  v0.8 Update: Aug 24, 2022 - zqevans\n",
        "      - Added Honk model\n",
        "      - Removed Rave Archive model\n",
        "      - Added sample length multipliers and batch sizes to regeneration and interpolation\n",
        "\n",
        "  v0.9 Update: Aug 24, 2022 - zqevans\n",
        "      - Added glitch.cool model\n",
        "      - Added jmann-large model\n",
        "      - Regenerated sounds are now output individually\n",
        "      - Added custom model sample_size and sample_rate options\n",
        "\n",
        "  v0.10 Update: Sep 26, 2022 - morganmcg1\n",
        "      - Added optional, off by default, Weights & Biases logging of the generated audio samples\n",
        "\n",
        "  v0.11 Update: Oct 27, 2022 - cosmicBboy\n",
        "      - Added a gradio audio recording widget in the \"Regenerate your own sounds\" section\n",
        "      \n",
        "  v0.12 Update: Nov 3, 2022 - zqevans\n",
        "      - Added k-diffusion samplers\n",
        "      - Added option to increase unconditional generation length\n",
        "    '''\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ufsXWZk4Nkv"
      },
      "source": [
        "# Install dependencies and restart notebook\n",
        "\n",
        "**The session will crash to restart automatically, don't worry about the error. This is to ensure the proper dependencies are installed**\n",
        "\n",
        "**Once the notebook restarts, continue with the steps below**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y9BS0ks1oEgP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70ccd607-750f-40ba-aa0d-e7d20dbd6cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sample-generator'...\n",
            "remote: Enumerating objects: 410, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 410 (delta 9), reused 14 (delta 5), pack-reused 389\u001b[K\n",
            "Receiving objects: 100% (410/410), 59.57 MiB | 40.69 MiB/s, done.\n",
            "Resolving deltas: 100% (234/234), done.\n",
            "Cloning into 'v-diffusion-pytorch'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (113/113), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 168 (delta 87), reused 77 (delta 62), pack-reused 55\u001b[K\n",
            "Receiving objects: 100% (168/168), 35.25 KiB | 1.53 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./sample-generator\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from sample-generator==1.0.0) (1.5.3)\n",
            "Collecting prefigure\n",
            "  Downloading prefigure-0.0.9-py3-none-any.whl (7.7 kB)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.1.post0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sample-generator==1.0.0) (1.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from sample-generator==1.0.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.9/dist-packages (from sample-generator==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sample-generator==1.0.0) (4.65.0)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->sample-generator==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas->sample-generator==1.0.0) (1.24.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->sample-generator==1.0.0) (2022.7.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.9/dist-packages (from prefigure->sample-generator==1.0.0) (0.5.0)\n",
            "Collecting configparser\n",
            "  Downloading configparser-5.3.0-py3-none-any.whl (19 kB)\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (23.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (6.0)\n",
            "Collecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->sample-generator==1.0.0) (3.11.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->sample-generator==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->sample-generator==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->sample-generator==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->sample-generator==1.0.0) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->sample-generator==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->sample-generator==1.0.0) (16.0.1)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (5.9.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (8.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (1.4.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (67.6.1)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->sample-generator==1.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb->sample-generator==1.0.0) (1.16.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->sample-generator==1.0.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->sample-generator==1.0.0) (1.3.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->sample-generator==1.0.0) (22.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: sample-generator, pathtools\n",
            "  Building wheel for sample-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sample-generator: filename=sample_generator-1.0.0-py3-none-any.whl size=9852 sha256=10041ffda802fc8ed01ce6e7cf2a0dc11f71cd6d033ac400394ab8c191177c2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ec/db/66a0fce3c708bf6a4b58926a82defd8e5bbbd64036f522f59a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=753340007c3441e73fe65e6643231d78264cf7c42eb00f57b00c48243e08f1dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built sample-generator pathtools\n",
            "Installing collected packages: pathtools, argparse, smmap, setproctitle, sentry-sdk, multidict, lightning-utilities, frozenlist, einops, docker-pycreds, configparser, async-timeout, yarl, gitdb, aiosignal, GitPython, aiohttp, wandb, torchmetrics, pytorch_lightning, prefigure, sample-generator\n",
            "Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 argparse-1.4.0 async-timeout-4.0.2 configparser-5.3.0 docker-pycreds-0.4.0 einops-0.6.0 frozenlist-1.3.3 gitdb-4.0.10 lightning-utilities-0.8.0 multidict-6.0.4 pathtools-0.1.2 prefigure-0.0.9 pytorch_lightning-2.0.1.post0 sample-generator-1.0.0 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 torchmetrics-0.11.4 wandb-0.14.2 yarl-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "configparser"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./v-diffusion-pytorch\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (4.65.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (0.15.1+cu118)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (8.4.0)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from v-diffusion-pytorch==0.0.2) (2.27.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->v-diffusion-pytorch==0.0.2) (0.2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->v-diffusion-pytorch==0.0.2) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->v-diffusion-pytorch==0.0.2) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->v-diffusion-pytorch==0.0.2) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->v-diffusion-pytorch==0.0.2) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (4.5.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->v-diffusion-pytorch==0.0.2) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->v-diffusion-pytorch==0.0.2) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->v-diffusion-pytorch==0.0.2) (3.25.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->v-diffusion-pytorch==0.0.2) (1.24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->v-diffusion-pytorch==0.0.2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->v-diffusion-pytorch==0.0.2) (1.3.0)\n",
            "Building wheels for collected packages: v-diffusion-pytorch\n",
            "  Building wheel for v-diffusion-pytorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for v-diffusion-pytorch: filename=v_diffusion_pytorch-0.0.2-py3-none-any.whl size=20526 sha256=d16e603642eeb0c37a3516fafca09301e21174a0a3540e207e049a2a470df8ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/41/fd/69d2bc56ba7eb0bc22eaebe6fd38563792790d9f91897c9585\n",
            "Successfully built v-diffusion-pytorch\n",
            "Installing collected packages: ftfy, v-diffusion-pytorch\n",
            "Successfully installed ftfy-6.1.1 v-diffusion-pytorch-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets==7.7.1 in /usr/local/lib/python3.9/dist-packages (7.7.1)\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.26.0-py3-none-any.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (7.34.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (3.6.4)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (3.0.7)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets==7.7.1) (5.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from gradio) (1.5.3)\n",
            "Collecting mdit-py-plugins<=0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from gradio) (3.8.4)\n",
            "Collecting semantic-version\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from gradio) (1.24.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from gradio) (4.5.0)\n",
            "Collecting huggingface-hub>=0.13.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from gradio) (6.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-11.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio) (2.1.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.10-cp39-cp39-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from gradio) (2.27.1)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (4.2.2)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio) (1.10.7)\n",
            "Collecting gradio-client==0.1.2\n",
            "  Downloading gradio_client-0.1.2-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from gradio-client==0.1.2->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from gradio-client==0.1.2->gradio) (23.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->gradio) (3.11.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.7.1) (6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.1.6)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (2.14.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (67.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (0.7.5)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets==7.7.1) (3.0.38)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1\n",
            "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.4.8)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Collecting starlette<0.27.0,>=0.26.1\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (3.4)\n",
            "Collecting httpcore<0.18.0,>=0.15.0\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (5.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets==7.7.1) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.5.4)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.16.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.17.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (5.8.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.3.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.5.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets==7.7.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets==7.7.1) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (3.2.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (21.2.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (6.0.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.2.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.2.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.7.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.11.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (4.9.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.16.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets==7.7.1) (2.21)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4707 sha256=0210bb4973e37223294cac588fe2f233b7f2d34199d1d2a5efe8ea804cd3193f\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, jedi, h11, aiofiles, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 fastapi-0.95.1 ffmpy-0.3.0 gradio-3.26.0 gradio-client-0.1.2 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.13.4 jedi-0.18.2 linkify-it-py-2.0.0 mdit-py-plugins-0.3.3 orjson-3.8.10 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.26.1 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting k-diffusion\n",
            "  Downloading k_diffusion-0.0.14-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (2.0.0+cu118)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (0.14.2)\n",
            "Collecting clean-fid\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (1.10.1)\n",
            "Collecting jsonmerge\n",
            "  Downloading jsonmerge-1.9.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting resize-right\n",
            "  Downloading resize_right-0.0.2-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (0.19.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (0.15.1+cu118)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (0.6.0)\n",
            "Collecting kornia\n",
            "  Downloading kornia-0.6.11-py2.py3-none-any.whl (628 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.1/628.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchsde\n",
            "  Downloading torchsde-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from k-diffusion) (8.4.0)\n",
            "Collecting clip-anytorch\n",
            "  Downloading clip_anytorch-2.5.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->k-diffusion) (1.24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->k-diffusion) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->k-diffusion) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->k-diffusion) (23.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->k-diffusion) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->k-diffusion) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->k-diffusion) (16.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from clean-fid->k-diffusion) (2.27.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from clip-anytorch->k-diffusion) (2022.10.31)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.9/dist-packages (from clip-anytorch->k-diffusion) (6.1.1)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonmerge->k-diffusion) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->k-diffusion) (2.25.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->k-diffusion) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->k-diffusion) (2023.3.21)\n",
            "Collecting boltons>=20.2.1\n",
            "  Downloading boltons-23.0.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trampoline>=0.1.2\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (1.4.4)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (1.3.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (3.1.31)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (1.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (67.6.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (3.20.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb->k-diffusion) (0.4.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb->k-diffusion) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion) (4.0.10)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion) (0.19.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->clean-fid->k-diffusion) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->clean-fid->k-diffusion) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->clean-fid->k-diffusion) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->clean-fid->k-diffusion) (2.0.12)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->clip-anytorch->k-diffusion) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->k-diffusion) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->k-diffusion) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion) (5.0.0)\n",
            "Building wheels for collected packages: jsonmerge\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.9.0-py3-none-any.whl size=18625 sha256=4afd73e4731b8c61c5937595993ec9f73e0d274930960ce1a8068b65bc4b0d57\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/0f/dd/bd5a8b81ed1feef7d08fea857f7bee591e481a484e6bee317a\n",
            "Successfully built jsonmerge\n",
            "Installing collected packages: trampoline, resize-right, boltons, jsonmerge, torchsde, torchdiffeq, kornia, clip-anytorch, clean-fid, accelerate, k-diffusion\n",
            "Successfully installed accelerate-0.18.0 boltons-23.0.0 clean-fid-0.1.35 clip-anytorch-2.5.2 jsonmerge-1.9.0 k-diffusion-0.0.14 kornia-0.6.11 resize-right-0.0.2 torchdiffeq-0.2.3 torchsde-0.2.5 trampoline-0.1.2\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output  \n",
        "import os, signal\n",
        "\n",
        "#@title Install and restart\n",
        "\n",
        "#@markdown \n",
        "\n",
        "!git clone https://github.com/harmonai-org/sample-generator\n",
        "!git clone --recursive https://github.com/crowsonkb/v-diffusion-pytorch\n",
        "!pip install /content/sample-generator\n",
        "!pip install /content/v-diffusion-pytorch\n",
        "!pip install ipywidgets==7.7.1 gradio\n",
        "!pip install k-diffusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU97ZiP7nSKS"
      },
      "source": [
        "# Setup\n",
        "Run everything in this section before any generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "mxb-qgh0nUOf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "693454fe-1a27-4919-e579-a262c385806d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-541e552545dc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msimple_nvidia_smi_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#!nvidia-smi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnvidiasmi_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-L'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnvidiasmi_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    949\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1819\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nvidia-smi'"
          ]
        }
      ],
      "source": [
        "#@title Check GPU Status\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "T_mFtzHvnlJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0962acce-92ff-4337-e122-a49fcf8d2a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab detected.\n",
            "Using Google Drive.\n",
            "Mounted at /content/drive\n",
            "\n",
            "Installing wandb...\n",
            "\n",
            "Please log in to Weights & Biases...\n",
            "1. Sign up for a free wandb account here: https://www.wandb.ai/site\n",
            "2. Enter your wandb API key, from https://wandb.ai/authorize, in the field below to log in: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 33\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "#@title Prepare folders\n",
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url, targetdir=None):\n",
        "    if targetdir:\n",
        "        res = subprocess.run(['git', 'clone', url, targetdir], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "        res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    # Using the !wget command instead of the subprocess to get the loading bar\n",
        "    !wget $url -O $outputdir\n",
        "    # res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    # print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected.\")\n",
        "    is_colab = True\n",
        "    #@markdown Check to connect your Google Drive\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    if google_drive:\n",
        "      print(\"Using Google Drive.\")\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        ai_root = '/content/drive/MyDrive/AI'\n",
        "        root_path = f'{ai_root}/Dance_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_audio'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/audio_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{ai_root}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)\n",
        "\n",
        "# libraries = f'{root_path}/libraries'\n",
        "# createPath(libraries)\n",
        "\n",
        "#@markdown Check the box below to save your generated audio to [Weights & Biases](https://wandb.ai/site)\n",
        "save_to_wandb = True #@param {type: \"boolean\"}\n",
        "\n",
        "if save_to_wandb:\n",
        "    print(\"\\nInstalling wandb...\")\n",
        "    os.system(\"pip install -qqq wandb --upgrade\")\n",
        "    import wandb\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "      wandb.login()\n",
        "    except:\n",
        "      print(\"\\nPlease log in to Weights & Biases...\")\n",
        "      print(\"1. Sign up for a free wandb account here: https://www.wandb.ai/site\")\n",
        "      print(\"2. Enter your wandb API key, from https://wandb.ai/authorize, in the field below to log in: \\n\")\n",
        "      wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMQ8vYNQO22Y"
      },
      "source": [
        "# Model settings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5tTfK51n-TO",
        "outputId": "2c3a1d67-59b9-4b2c-8500-bb69b708e24e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: torch_xla-1.9-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.9/dist-packages (2.0.1.post0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.24.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (0.8.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "haxvUGZ0VpzA"
      },
      "outputs": [],
      "source": [
        "#@title Imports and definitions\n",
        "from prefigure.prefigure import get_all_args\n",
        "from contextlib import contextmanager\n",
        "from copy import deepcopy\n",
        "import math\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "import os, signal, sys\n",
        "import gc\n",
        "\n",
        "from diffusion import sampling\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "from einops import rearrange\n",
        "\n",
        "import torchaudio\n",
        "from audio_diffusion.models import DiffusionAttnUnet1D\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "from audio_diffusion.utils import Stereo, PadCrop\n",
        "from glob import glob\n",
        "\n",
        "#@title Model code\n",
        "class DiffusionUncond(nn.Module):\n",
        "    def __init__(self, global_args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.diffusion = DiffusionAttnUnet1D(global_args, n_attn_layers = 4)\n",
        "        self.diffusion_ema = deepcopy(self.diffusion)\n",
        "        self.rng = torch.quasirandom.SobolEngine(1, scramble=True)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "\n",
        "def plot_and_hear(audio, sr):\n",
        "    display(ipd.Audio(audio.cpu().clamp(-1, 1), rate=sr))\n",
        "    plt.plot(audio.cpu().t().numpy())\n",
        "  \n",
        "def load_to_device(path, sr):\n",
        "    audio, file_sr = torchaudio.load(path)\n",
        "    if sr != file_sr:\n",
        "      audio = torchaudio.transforms.Resample(file_sr, sr)(audio)\n",
        "    audio = audio.to(device)\n",
        "    return audio\n",
        "\n",
        "def get_alphas_sigmas(t):\n",
        "    \"\"\"Returns the scaling factors for the clean image (alpha) and for the\n",
        "    noise (sigma), given a timestep.\"\"\"\n",
        "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
        "\n",
        "def get_crash_schedule(t):\n",
        "    sigma = torch.sin(t * math.pi / 2) ** 2\n",
        "    alpha = (1 - sigma ** 2) ** 0.5\n",
        "    return alpha_sigma_to_t(alpha, sigma)\n",
        "\n",
        "def t_to_alpha_sigma(t):\n",
        "    \"\"\"Returns the scaling factors for the clean image and for the noise, given\n",
        "    a timestep.\"\"\"\n",
        "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)\n",
        "\n",
        "def alpha_sigma_to_t(alpha, sigma):\n",
        "    \"\"\"Returns a timestep, given the scaling factors for the clean image and for\n",
        "    the noise.\"\"\"\n",
        "    return torch.atan2(sigma, alpha) / math.pi * 2\n",
        "\n",
        "#@title Args\n",
        "sample_size = 65536 \n",
        "sample_rate = 48000   \n",
        "latent_dim = 0             \n",
        "\n",
        "class Object(object):\n",
        "    pass\n",
        "\n",
        "args = Object()\n",
        "args.sample_size = sample_size\n",
        "args.sample_rate = sample_rate\n",
        "args.latent_dim = latent_dim\n",
        "\n",
        "#@title Logging\n",
        "def get_one_channel(audio_data, channel):\n",
        "  '''\n",
        "  Takes a numpy audio array and returns 1 channel\n",
        "  '''\n",
        "  # Check if the audio has more than 1 channel \n",
        "  if len(audio_data.shape) > 1:\n",
        "    is_stereo = True      \n",
        "    if np.argmax(audio_data.shape)==0:\n",
        "        audio_data = audio_data[:,channel] \n",
        "    else:\n",
        "        audio_data = audio_data[channel,:]\n",
        "  else:\n",
        "    is_stereo = False\n",
        "\n",
        "  return audio_data\n",
        "\n",
        "def log_audio_to_wandb(\n",
        "    generated, model_name, custom_ckpt_path, steps, batch_size, sample_rate, sample_size, \n",
        "    generated_all=None, channel=0, original_sample=None, gen_type='new_sounds', noise_level=None, sample_length_mult=None, file_path=None\n",
        "    ):\n",
        "\n",
        "    print('\\nSaving your audio generations to Weights & Biases...')\n",
        "\n",
        "    # Get model name\n",
        "    if model_name == \"custom\":\n",
        "      wandb_model_name = custom_ckpt_path\n",
        "    else:\n",
        "      wandb_model_name = model_name\n",
        "    \n",
        "    # Create config to log to wandb\n",
        "    wandb_config = {\n",
        "      \"model\":model_name,\n",
        "      \"steps\":steps,\n",
        "      \"batch_size\":batch_size,\n",
        "      \"sample_rate\":sample_rate,\n",
        "      \"sample_size\":sample_size,\n",
        "      \"channel\":channel,\n",
        "      \"gen_type\":gen_type,\n",
        "      \"noise_level\":noise_level,\n",
        "      \"sample_length_mult\":sample_length_mult,\n",
        "      \"file_path\":file_path\n",
        "    }\n",
        "\n",
        "    # Create a new wandb run\n",
        "    wandb.init(project='harmonai-audio-gen', config=wandb_config)\n",
        "    wandb_run_url = wandb.run.get_url()\n",
        "\n",
        "    # Create a Weights & Biases Table\n",
        "    audio_generations_table = wandb.Table(columns=['audio', 'steps', 'model', 'batch_size', \n",
        "      'sample_rate', 'sample_size', 'duration'])\n",
        "\n",
        "    # Add each individual generated sample to a wandb Table\n",
        "    for idx, g in enumerate(generated.cpu().numpy()):\n",
        "    \n",
        "      # Check if the audio has more than 1 channel \n",
        "      if idx==0:  \n",
        "        if len(g.shape) > 1:\n",
        "          stereo = True      \n",
        "        else:\n",
        "          stereo = False\n",
        "\n",
        "      if stereo:\n",
        "        g = g[channel]\n",
        "\n",
        "      duration = np.max(g.shape) / sample_rate \n",
        "      wandb_audio =  wandb.Audio(g, sample_rate=sample_rate, caption=wandb_model_name)\n",
        "      audio_generations_table.add_data(wandb_audio, steps, wandb_model_name, batch_size, \n",
        "        sample_rate, sample_size, duration)\n",
        "\n",
        "    # Log the samples Tables and finish the wandb run\n",
        "    wandb.log({f'{gen_type}/harmonai_generations' : audio_generations_table})\n",
        "    \n",
        "    # Log the combined samples in another wandb Table\n",
        "    if generated_all is not None:\n",
        "      g_all = get_one_channel(generated_all, channel)\n",
        "      duration_all = np.max(g_all.shape) / sample_rate \n",
        "      audio_all_generations_table = wandb.Table(columns=['audio', 'steps', 'model', 'batch_size', \n",
        "        'sample_rate', 'sample_size', 'duration'])\n",
        "      wandb_all_audio = wandb.Audio(g_all.cpu().numpy(), sample_rate=sample_rate, caption=wandb_model_name)\n",
        "      audio_all_generations_table.add_data(wandb_all_audio, steps, wandb_model_name, batch_size, \n",
        "        sample_rate, sample_size, duration_all)\n",
        "      wandb.log({f'{gen_type}/all_harmonai_generations' : audio_all_generations_table})\n",
        "\n",
        "    if original_sample is not None:\n",
        "      original_sample = get_one_channel(original_sample, channel)\n",
        "      audio_original_sample_table = wandb.Table(columns=['audio', 'file_path'])\n",
        "      wandb_original_audio = wandb.Audio(original_sample, sample_rate=sample_rate)\n",
        "      audio_original_sample_table.add_data(wandb_original_audio, file_path)\n",
        "      wandb.log({f'{gen_type}/original_sample' : audio_original_sample_table})\n",
        "    \n",
        "    wandb.finish()\n",
        "\n",
        "    print(f'Your audio generations are saved in Weights & Biases here: {wandb_run_url}\\n')\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWxBqHH_Yjvt"
      },
      "source": [
        "Select the model you want to sample from\n",
        "---\n",
        "Model name | Description | Sample rate | Output samples\n",
        "--- | --- | --- | ---\n",
        "glitch-440k |Trained on clips from samples provided by [glitch.cool](https://glitch.cool) | 48000 | 65536\n",
        "jmann-small-190k |Trained on clips from Jonathan Mann's [Song-A-Day](https://songaday.world/) project | 48000 | 65536\n",
        "jmann-large-580k |Trained on clips from Jonathan Mann's [Song-A-Day](https://songaday.world/) project | 48000 | 131072\n",
        "maestro-150k |Trained on piano clips from the [MAESTRO](https://magenta.tensorflow.org/datasets/maestro) dataset | 16000 | 65536\n",
        "unlocked-250k |Trained on clips from the [Unlocked Recordings](https://archive.org/details/unlockedrecordings) dataset | 16000 | 65536\n",
        "honk-140k |Trained on recordings of the Canada Goose from [xeno-canto](https://xeno-canto.org/) | 16000 | 65536\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JHsHQcc6rHu7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "ab4f2c83-9b07-46bb-a1c1-969d0af1ab9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glitch-440k already downloaded. If the file is corrupt, enable check_model_SHA.\n",
            "Creating the model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-91230af78478>\u001b[0m in \u001b[0;36m<cell line: 112>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating the model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiffusionUncond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model created\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         typed_storage = torch.storage.TypedStorage(\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0mwrap_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             _internal=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    167\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "from urllib.parse import urlparse\n",
        "import hashlib\n",
        "import k_diffusion as K\n",
        "\n",
        "#@title Create the model\n",
        "model_name = \"glitch-440k\" #@param [\"glitch-440k\", \"jmann-small-190k\", \"jmann-large-580k\", \"maestro-150k\", \"unlocked-250k\", \"honk-140k\", \"custom\"]\n",
        "\n",
        "#@markdown ###Custom options\n",
        "\n",
        "#@markdown If you have a custom fine-tuned model, choose \"custom\" above and enter a path to the model checkpoint here\n",
        "\n",
        "#@markdown These options will not affect non-custom models\n",
        "custom_ckpt_path = ''#@param {type: 'string'}\n",
        "\n",
        "custom_sample_rate = 16000 #@param {type: 'number'}\n",
        "custom_sample_size = 65536 #@param {type: 'number'}\n",
        "\n",
        "models_map = {\n",
        "\n",
        "    \"glitch-440k\": {'downloaded': False,\n",
        "                         'sha': \"48caefdcbb7b15e1a0b3d08587446936302535de74b0e05e0d61beba865ba00a\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/gwf-440k.ckpt\"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"jmann-small-190k\": {'downloaded': False,\n",
        "                         'sha': \"1e2a23a54e960b80227303d0495247a744fa1296652148da18a4da17c3784e9b\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/jmann-small-190k.ckpt\"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"jmann-large-580k\": {'downloaded': False,\n",
        "                         'sha': \"6b32b5ff1c666c4719da96a12fd15188fa875d6f79f8dd8e07b4d54676afa096\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/jmann-large-580k.ckpt\"],\n",
        "                         'sample_rate': 48000,\n",
        "                         'sample_size': 131072\n",
        "                         },\n",
        "    \"maestro-150k\": {'downloaded': False,\n",
        "                         'sha': \"49d9abcae642e47c2082cec0b2dce95a45dc6e961805b6500204e27122d09485\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/maestro-uncond-150k.ckpt\"],\n",
        "                         'sample_rate': 16000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"unlocked-250k\": {'downloaded': False,\n",
        "                         'sha': \"af337c8416732216eeb52db31dcc0d49a8d48e2b3ecaa524cb854c36b5a3503a\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/unlocked-uncond-250k.ckpt\"],\n",
        "                         'sample_rate': 16000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "    \"honk-140k\": {'downloaded': False,\n",
        "                         'sha': \"a66847844659d287f55b7adbe090224d55aeafdd4c2b3e1e1c6a02992cb6e792\", \n",
        "                         'uri_list': [\"https://model-server.zqevans2.workers.dev/honk-140k.ckpt\"],\n",
        "                         'sample_rate': 16000,\n",
        "                         'sample_size': 65536\n",
        "                         },\n",
        "}\n",
        "\n",
        "#@markdown If you're having issues with model downloads, check this to compare the SHA:\n",
        "check_model_SHA = False #@param{type:\"boolean\"}\n",
        "\n",
        "def get_model_filename(diffusion_model_name):\n",
        "    model_uri = models_map[diffusion_model_name]['uri_list'][0]\n",
        "    model_filename = os.path.basename(urlparse(model_uri).path)\n",
        "    return model_filename\n",
        "\n",
        "def download_model(diffusion_model_name, uri_index=0):\n",
        "    if diffusion_model_name != 'custom':\n",
        "        model_filename = get_model_filename(diffusion_model_name)\n",
        "        model_local_path = os.path.join(model_path, model_filename)\n",
        "        if os.path.exists(model_local_path) and check_model_SHA:\n",
        "            print(f'Checking {diffusion_model_name} File')\n",
        "            with open(model_local_path, \"rb\") as f:\n",
        "                bytes = f.read() \n",
        "                hash = hashlib.sha256(bytes).hexdigest()\n",
        "                print(f'SHA: {hash}')\n",
        "            if hash == models_map[diffusion_model_name]['sha']:\n",
        "                print(f'{diffusion_model_name} SHA matches')\n",
        "                models_map[diffusion_model_name]['downloaded'] = True\n",
        "            else:\n",
        "                print(f\"{diffusion_model_name} SHA doesn't match. Will redownload it.\")\n",
        "        elif os.path.exists(model_local_path) and not check_model_SHA or models_map[diffusion_model_name]['downloaded']:\n",
        "            print(f'{diffusion_model_name} already downloaded. If the file is corrupt, enable check_model_SHA.')\n",
        "            models_map[diffusion_model_name]['downloaded'] = True\n",
        "\n",
        "        if not models_map[diffusion_model_name]['downloaded']:\n",
        "            for model_uri in models_map[diffusion_model_name]['uri_list']:\n",
        "                wget(model_uri, model_local_path)\n",
        "                with open(model_local_path, \"rb\") as f:\n",
        "                  bytes = f.read() \n",
        "                  hash = hashlib.sha256(bytes).hexdigest()\n",
        "                  print(f'SHA: {hash}')\n",
        "                if os.path.exists(model_local_path):\n",
        "                    models_map[diffusion_model_name]['downloaded'] = True\n",
        "                    return\n",
        "                else:\n",
        "                    print(f'{diffusion_model_name} model download from {model_uri} failed. Will try any fallback uri.')\n",
        "            print(f'{diffusion_model_name} download failed.')\n",
        "\n",
        "if model_name == \"custom\":\n",
        "  ckpt_path = custom_ckpt_path\n",
        "  args.sample_size = custom_sample_size\n",
        "  args.sample_rate = custom_sample_rate\n",
        "else:\n",
        "  model_info = models_map[model_name]\n",
        "  download_model(model_name)\n",
        "  ckpt_path = f'{model_path}/{get_model_filename(model_name)}'\n",
        "  args.sample_size = model_info[\"sample_size\"]\n",
        "  args.sample_rate = model_info[\"sample_rate\"]\n",
        "\n",
        "print(\"Creating the model...\")\n",
        "model = DiffusionUncond(args)\n",
        "torch.load(torch.load(ckpt_path)[\"state_dict\"], map_location=torch.device(\"cpu\"))\n",
        "model = model.requires_grad_(False).to(\"cpu\")\n",
        "print(\"Model created\")\n",
        "\n",
        "# # Remove non-EMA\n",
        "del model.diffusion\n",
        "\n",
        "model_fn = model.diffusion_ema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knzr6CYmtaI_"
      },
      "source": [
        "Select the sampler you want to use\n",
        "---\n",
        "Sampler name | Notes\n",
        "--- | ---\n",
        "v-ddim | This is the sampler used in the training notebook. Needs more steps, but more reliable.\n",
        "v-iplms | Similar to above, but sometimes lower quality.\n",
        "k-heun | Needs fewer steps, but ideal sigma_min and sigma_max need to be found. Doesn't work with all models.\n",
        "k-dpmpp_2s_ancestral | Fastest sampler, but you may have to find new sigmas. Recommended min & max sigmas: 0.01, 80\n",
        "k-lms | \"\n",
        "k-dpm-2 | \"\n",
        "k-dpm-fast | \"\n",
        "k-dpm-adaptive | Takes in extra parameters for quality, step count is non-deterministic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyR4w86-ei_z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Sampler options\n",
        "sampler_type = \"v-ddim\" #@param [\"v-ddim\", \"v-iplms\", \"k-heun\", \"k-dpmpp_2s_ancestral\", \"k-lms\", \"k-dpm-2\", \"k-dpm-fast\", \"k-dpm-adaptive\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown <h3>Advanced settings</h3>\n",
        "#@markdown \n",
        "#@markdown **V-diffusion settings**\n",
        "eta = 0 #@param {type: \"number\"}\n",
        "#@markdown **K-diffusion settings**\n",
        "sigma_min = 0.0001 #@param {type: \"number\"}\n",
        "sigma_max = 1 #@param {type: \"number\"}\n",
        "rho=7. #@param {type: \"number\"}\n",
        "#@markdown k-dpm-adaptive settings\n",
        "rtol = 0.01 #@param {type: \"number\"}\n",
        "atol = 0.01 #@param {type: \"number\"}\n",
        "\n",
        "def sample(model_fn, noise, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  #Check for k-diffusion\n",
        "  if sampler_type.startswith('k-'):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, sigma_max, rho, device=device)\n",
        "\n",
        "  elif sampler_type.startswith(\"v-\"):\n",
        "    t = torch.linspace(1, 0, steps + 1, device=device)[:-1]\n",
        "    step_list = get_crash_schedule(t)\n",
        "\n",
        "  if sampler_type == \"v-ddim\":\n",
        "    return sampling.sample(model_fn, noise, step_list, eta, {})\n",
        "  elif sampler_type == \"v-iplms\":\n",
        "    return sampling.iplms_sample(model_fn, noise, step_list, {})\n",
        "\n",
        "  elif sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, noise, sigmas, disable=False)\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, noise, sigma_min, sigma_max, steps, disable=False)\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, noise, sigma_min, sigma_max, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "def resample(model_fn, audio, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  #Noise the input\n",
        "\n",
        "  if sampler_type.startswith(\"v-\"):\n",
        "    t = torch.linspace(0, 1, steps + 1, device=device)\n",
        "    step_list = get_crash_schedule(t)\n",
        "    step_list = step_list[step_list < noise_level]\n",
        "\n",
        "    alpha, sigma = t_to_alpha_sigma(step_list[-1])\n",
        "    noised = torch.randn([batch_size, 2, effective_length], device='cuda')\n",
        "    noised = audio * alpha + noised * sigma\n",
        "    noise = noised\n",
        "\n",
        "  elif sampler_type.startswith(\"k-\"):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    noised = audio + torch.randn_like(audio) * noise_level\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, noise_level, rho, device=device)\n",
        "\n",
        "  # Denoise\n",
        "  if sampler_type == \"v-iplms\":\n",
        "    return sampling.iplms_sample(model_fn, noised, step_list.flip(0)[:-1], {})\n",
        "\n",
        "  if sampler_type == \"v-ddim\":\n",
        "    return sampling.sample(model_fn, noise, step_list.flip(0)[:-1], eta, {})\n",
        "\n",
        "  elif sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, noised, sigmas, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, noised, sigmas, s_noise=0., disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, noised, sigma_min, noise_level, steps, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, noised, sigma_min, noise_level, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "def reverse_sample(model_fn, audio, steps=100, sampler_type=\"v-iplms\", noise_level = 1.0):\n",
        "  \n",
        "  if sampler_type.startswith(\"v-\"):\n",
        "    t = torch.linspace(0, 1, steps + 1, device=device)\n",
        "    step_list = get_crash_schedule(t)\n",
        "\n",
        "    if sampler_type == \"v-iplms\":\n",
        "      return sampling.iplms_sample(model_fn, audio_samples, step_list, {}, is_reverse=True)\n",
        "\n",
        "    if sampler_type == \"v-ddim\":\n",
        "      return sampling.sample(model_fn, noise, step_list, eta, {}, is_reverse=True)\n",
        "\n",
        "  elif sampler_type.startswith(\"k-\"):\n",
        "    denoiser = K.external.VDenoiser(model_fn)\n",
        "    sigmas = K.sampling.get_sigmas_karras(steps, sigma_min, noise_level, rho, device=device)\n",
        "\n",
        "  # Denoise\n",
        "  if sampler_type == \"k-heun\":\n",
        "    return K.sampling.sample_heun(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-lms\":\n",
        "    return K.sampling.sample_lms(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-dpmpp_2s_ancestral\":\n",
        "    return K.sampling.sample_dpmpp_2s_ancestral(denoiser, audio, sigmas.flip(0)[:-1], disable=False)\n",
        "  elif sampler_type == \"k-dpm-2\":\n",
        "    return K.sampling.sample_dpm_2(denoiser, audio, sigmas.flip(0)[:-1], s_noise=0., disable=False)\n",
        "  elif sampler_type == \"k-dpm-fast\":\n",
        "    return K.sampling.sample_dpm_fast(denoiser, audio, noise_level, sigma_min, steps, disable=False)\n",
        "\n",
        "  elif sampler_type == \"k-dpm-adaptive\":\n",
        "    return K.sampling.sample_dpm_adaptive(denoiser, audio, noise_level, sigma_min, rtol=rtol, atol=atol, disable=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GQK9yZHTr_z"
      },
      "source": [
        "# Generate new sounds\n",
        "\n",
        "Feeding white noise into the model to be denoised creates novel sounds in the \"space\" of the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zntGqLTJq6xU"
      },
      "outputs": [],
      "source": [
        "#@markdown How many audio clips to create\n",
        "batch_size =  4#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of steps (100 is a good start, more steps trades off speed for quality)\n",
        "steps = 100 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Multiplier on the default sample length from the model, allows for longer audio clips at the expense of VRAM\n",
        "sample_length_mult = 1#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Check the box below to save your generated audio to [Weights & Biases](https://www.wandb.ai/site)\n",
        "save_new_generations_to_wandb = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown Check the box below to skip this section when running all cells\n",
        "skip_for_run_all = False #@param {type: \"boolean\"}\n",
        "\n",
        "effective_length = sample_length_mult * args.sample_size\n",
        "\n",
        "if not skip_for_run_all:\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  # Generate random noise to sample from\n",
        "  noise = torch.randn([batch_size, 2, effective_length]).to(\"xla\")\n",
        "\n",
        "  generated = sample(model_fn, noise, steps, sampler_type)\n",
        "\n",
        "  # Hard-clip the generated audio\n",
        "  generated = generated.clamp(-1, 1)\n",
        "\n",
        "  # Put the demos together\n",
        "  generated_all = rearrange(generated, 'b d n -> d (b n)')\n",
        "\n",
        "  print(\"All samples\")\n",
        "  plot_and_hear(generated_all, args.sample_rate)\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "\n",
        "  # If Weights & Biases logging enabled, save generations\n",
        "  if save_new_generations_to_wandb:\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "\n",
        "      log_audio_to_wandb(generated, model_name, custom_ckpt_path, steps, batch_size, \n",
        "      args.sample_rate, args.sample_size, generated_all=generated_all)\n",
        "    except:\n",
        "      print(\"Not logged in to Weights & Biases, please tick the `save_to_wandb` box at the top of this notebook and run that cell again to log in to Weights & Biases first\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0WKP7ku67vn"
      },
      "source": [
        "# Regenerate your own sounds\n",
        "By adding noise to an audio file and running it through the model to be denoised, new details will be created, pulling the audio closer to the \"sonic space\" of the model. The more noise you add, the more the sound will change.\n",
        "\n",
        "The effect of this is a kind of \"style transfer\" on the audio. For those familiar with image generation models, this is analogous to an \"init image\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oTK_JxQ0arky"
      },
      "outputs": [],
      "source": [
        "#@title Record audio or enter a filepath to a prerecorded audio file\n",
        "import torch\n",
        "import torchaudio\n",
        "from typing import Iterable, Tuple\n",
        "import gradio as gr\n",
        "\n",
        "Audio = Tuple[int, np.ndarray]\n",
        "\n",
        "#@markdown Check the box below to create an audio recording interface below\n",
        "record_audio = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown If you left \"record_audio\" blank, enter a path to an audio file you want to alter, or leave blank to upload a file (.wav or .flac).\n",
        "file_path = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown Number of audio recordings to combine into one clip. Only applies if the \"record_audio\" box is checked.\n",
        "n_audio_recordings = 1 #@param{type:\"number\"}\n",
        "\n",
        "# this is a global variable to be filled in by the generate_from_audio callback\n",
        "recording_file_path = \"\"\n",
        "\n",
        "\n",
        "def combine_audio(*audio_iterable: Iterable[Audio]) -> Audio:\n",
        "    \"\"\"Combines an iterable of audio signals into one.\"\"\"\n",
        "    max_len = max([x.shape for _, x in audio_iterable])\n",
        "    combined_audio = np.zeros(max_len, dtype=np.int32)\n",
        "    for _, a in audio_iterable:\n",
        "        combined_audio[:a.shape[0]] = combined_audio[:a.shape[0]] * .5 + a * .5\n",
        "    return combined_audio\n",
        "\n",
        "\n",
        "def generate_from_audio(file_path: str, *audio_iterable: Iterable[Audio]):\n",
        "    sample_rate = audio_iterable[0][0]\n",
        "    combined_audio = combine_audio(*audio_iterable)\n",
        "    tensor = torch.from_numpy(\n",
        "        np.concatenate(\n",
        "            [\n",
        "                combined_audio.reshape(1, -1),\n",
        "                combined_audio.reshape(1, -1)\n",
        "            ],\n",
        "            axis=0,\n",
        "        )\n",
        "    )\n",
        "    global recording_file_path\n",
        "    recording_file_path = file_path\n",
        "    torchaudio.save(\n",
        "        file_path,\n",
        "        tensor,\n",
        "        sample_rate=sample_rate,\n",
        "        format=\"wav\"\n",
        "    )\n",
        "    return (sample_rate, combined_audio), file_path\n",
        "\n",
        "if record_audio:\n",
        "    recording_interface = gr.Interface(\n",
        "        fn=generate_from_audio,\n",
        "        inputs=[\n",
        "            gr.Textbox(\n",
        "                \"/content/recording.wav\",\n",
        "                label=\"save recording to filepath\",\n",
        "            ),\n",
        "            *[\n",
        "                gr.Audio(source=\"microphone\", label=f\"audio clip {i}\")\n",
        "                for i in range(1, n_audio_recordings + 1)\n",
        "            ]\n",
        "        ],\n",
        "        outputs=[\n",
        "            gr.Audio(label=\"combined output audio\"),\n",
        "            gr.File(label=\"output file\"),\n",
        "        ],\n",
        "        allow_flagging=\"never\",\n",
        "    )\n",
        "\n",
        "    recording_interface.launch();\n",
        "elif file_path == \"\":\n",
        "    print(\"No file path provided, please upload a file\")\n",
        "    # uploaded = files.upload()\n",
        "    file_path = list(uploaded.keys())[0]\n",
        "\n",
        "if not record_audio:\n",
        "    print(f\"Using file_path: {file_path} to regenerate new sounds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKgS7vZc4lN9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Generate new sounds from recording\n",
        "\n",
        "#@markdown Total number of steps (100 is a good start, more steps trades off speed for quality)\n",
        "steps = 100#@param {type:\"number\"}\n",
        "\n",
        "#@markdown How much (0-1) to re-noise the original sample. Adding more noise (a higher number) means a bigger change to the input audio\n",
        "noise_level = 0.3#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Multiplier on the default sample length from the model, allows for longer audio clips at the expense of VRAM\n",
        "sample_length_mult = 2#@param {type:\"number\"}\n",
        "\n",
        "#@markdown How many variations to create\n",
        "batch_size = 4 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Check the box below to save your generated audio to [Weights & Biases](https://www.wandb.ai/site)\n",
        "save_own_generations_to_wandb = False #@param {type: \"boolean\"}\n",
        "\n",
        "#@markdown Check the box below to skip this section when running all cells\n",
        "skip_for_run_all = False #@param {type: \"boolean\"}\n",
        "\n",
        "effective_length = args.sample_size * sample_length_mult\n",
        "\n",
        "if not skip_for_run_all:\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  augs = torch.nn.Sequential(\n",
        "    PadCrop(effective_length, randomize=True),\n",
        "    Stereo()\n",
        "  )\n",
        "\n",
        "  fp = recording_file_path if record_audio else file_path\n",
        "\n",
        "  audio_sample = load_to_device(fp, args.sample_rate)\n",
        "\n",
        "  audio_sample = augs(audio_sample).unsqueeze(0).repeat([batch_size, 1, 1])\n",
        "\n",
        "  print(\"Initial audio sample\")\n",
        "  plot_and_hear(audio_sample[0], args.sample_rate)\n",
        "  \n",
        "  generated = resample(model_fn, audio_sample, steps, sampler_type, noise_level=noise_level)\n",
        "\n",
        "  print(\"Regenerated audio samples\")\n",
        "  plot_and_hear(rearrange(generated, 'b d n -> d (b n)'), args.sample_rate)\n",
        "\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "\n",
        "  # If Weights & Biases logging enabled, save generations\n",
        "  if save_own_generations_to_wandb:\n",
        "    # Check if logged in to wandb\n",
        "    try:\n",
        "      import netrc\n",
        "      netrc.netrc().hosts['api.wandb.ai']\n",
        "\n",
        "      log_audio_to_wandb(generated, model_name, custom_ckpt_path, steps, batch_size, \n",
        "        args.sample_rate, args.sample_size, file_path=fp, original_sample=audio_sample[0].cpu().numpy(),\n",
        "        noise_level=noise_level, gen_type='own_file')\n",
        "    except:\n",
        "      print(\"Not logged in to Weights & Biases, please tick the `save_to_wandb` box at the top of this notebook and run that cell again to log in to Weights & Biases first\")\n",
        "\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW8N8GCCM-yT"
      },
      "source": [
        "# Interpolate between sounds\n",
        "Diffusion models allow for interpolation between inputs through a process of deterministic noising and denoising. \n",
        "\n",
        "By deterministically noising two audio files, interpolating between the results, and deterministically denoising them, we can can create new sounds \"between\" the audio files provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "l3Al3thgO5rb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "6a621e50-debd-4f83-ee53-8ba43e1d3050"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-04326b20d333>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mskip_for_run_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m#@param {type: \"boolean\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0meffective_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msample_length_mult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_for_run_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ],
      "source": [
        "# Interpolation code taken and modified from CRASH\n",
        "def compute_interpolation_in_latent(latent1, latent2, lambd):\n",
        "    '''\n",
        "    Implementation of Spherical Linear Interpolation: https://en.wikipedia.org/wiki/Slerp\n",
        "    latent1: tensor of shape (2, n)\n",
        "    latent2: tensor of shape (2, n)\n",
        "    lambd: list of floats between 0 and 1 representing the parameter t of the Slerp\n",
        "    '''\n",
        "    device = latent1.device\n",
        "    lambd = torch.tensor(lambd)\n",
        "\n",
        "    assert(latent1.shape[0] == latent2.shape[0])\n",
        "\n",
        "    # get the number of channels\n",
        "    nc = latent1.shape[0]\n",
        "    interps = []\n",
        "    for channel in range(nc):\n",
        "    \n",
        "      cos_omega = latent1[channel]@latent2[channel] / \\\n",
        "          (torch.linalg.norm(latent1[channel])*torch.linalg.norm(latent2[channel]))\n",
        "      omega = torch.arccos(cos_omega).item()\n",
        "\n",
        "      a = torch.sin((1-lambd)*omega) / np.sin(omega)\n",
        "      b = torch.sin(lambd*omega) / np.sin(omega)\n",
        "      a = a.unsqueeze(1).to(device)\n",
        "      b = b.unsqueeze(1).to(device)\n",
        "      interps.append(a * latent1[channel] + b * latent2[channel])\n",
        "    return rearrange(torch.cat(interps), \"(c b) n -> b c n\", c=nc) \n",
        "\n",
        "#@markdown Enter the paths to two audio files to interpolate between (.wav or .flac)\n",
        "source_audio_path = \"\" #@param{type:\"string\"}\n",
        "target_audio_path = \"\" #@param{type:\"string\"}\n",
        "\n",
        "#@markdown Total number of steps (100 is a good start, can go lower for more speed/less quality)\n",
        "steps = 100#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of interpolated samples\n",
        "n_interps = 12 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Multiplier on the default sample length from the model, allows for longer audio clips at the expense of VRAM\n",
        "sample_length_mult = 1#@param {type:\"number\"}\n",
        "\n",
        "#@markdown Check the box below to skip this section when running all cells\n",
        "skip_for_run_all = True #@param {type: \"boolean\"}\n",
        "\n",
        "effective_length = args.sample_size * sample_length_mult\n",
        "\n",
        "if not skip_for_run_all:\n",
        "\n",
        "  augs = torch.nn.Sequential(\n",
        "    PadCrop(effective_length, randomize=True),\n",
        "    Stereo()\n",
        "  )\n",
        "\n",
        "  if source_audio_path == \"\":\n",
        "    print(\"No file path provided for the source audio, please upload a file\")\n",
        "    uploaded = files.upload()\n",
        "    source_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "  audio_sample_1 = load_to_device(source_audio_path, args.sample_rate)\n",
        "\n",
        "  print(\"Source audio sample loaded\")\n",
        "\n",
        "  if target_audio_path == \"\":\n",
        "    print(\"No file path provided for the target audio, please upload a file\")\n",
        "    uploaded = files.upload()\n",
        "    target_audio_path = list(uploaded.keys())[0]\n",
        "\n",
        "  audio_sample_2 = load_to_device(target_audio_path, args.sample_rate)\n",
        "\n",
        "  print(\"Target audio sample loaded\")\n",
        "\n",
        "  audio_samples = augs(audio_sample_1).unsqueeze(0).repeat([2, 1, 1])\n",
        "  audio_samples[1] = augs(audio_sample_2)\n",
        "\n",
        "  print(\"Initial audio samples\")\n",
        "  plot_and_hear(audio_samples[0], args.sample_rate)\n",
        "  plot_and_hear(audio_samples[1], args.sample_rate)\n",
        "\n",
        "  reversed = reverse_sample(model_fn, audio_samples, steps)\n",
        "\n",
        "  latent_series = compute_interpolation_in_latent(reversed[0], reversed[1], [k/n_interps for k in range(n_interps + 2)])\n",
        "\n",
        "  generated = sample(model_fn, latent_series, steps) \n",
        "  \n",
        "  #sampling.iplms_sample(, latent_series, step_list.flip(0)[:-1], {})\n",
        "\n",
        "  # Put the demos together\n",
        "  generated_all = rearrange(generated, 'b d n -> d (b n)')\n",
        "\n",
        "  print(\"Full interpolation\")\n",
        "  plot_and_hear(generated_all, args.sample_rate)\n",
        "  for ix, gen_sample in enumerate(generated):\n",
        "    print(f'sample #{ix + 1}')\n",
        "    display(ipd.Audio(gen_sample.cpu(), rate=args.sample_rate))\n",
        "else:\n",
        "  print(\"Skipping section, uncheck 'skip_for_run_all' to enable\") "
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}